# ç¿»è¯‘åŠŸèƒ½å¼€å‘æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†é¡¹ç›®ä¸­ç¿»è¯‘åŠŸèƒ½çš„æŠ€æœ¯å®ç°ã€æ¶æ„è®¾è®¡å’Œå¼€å‘æŒ‡å—ã€‚ç¿»è¯‘åŠŸèƒ½æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼ŒåŒ…æ‹¬PDFã€PPTã€Wordç­‰ï¼Œå¹¶é›†æˆäº†å¤šä¸ªç¿»è¯‘å¼•æ“ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

```
ç¿»è¯‘ç³»ç»Ÿæ¶æ„
â”œâ”€â”€ æ–‡æ¡£è§£æå±‚ (Document Parsers)
â”‚   â”œâ”€â”€ PDFParser - PDFæ–‡æ¡£è§£æ
â”‚   â”œâ”€â”€ PPTParser - PowerPointè§£æ
â”‚   â””â”€â”€ WordParser - Wordæ–‡æ¡£è§£æ
â”œâ”€â”€ ç¿»è¯‘å¼•æ“å±‚ (Translation Engines)
â”‚   â”œâ”€â”€ OpenAITranslator - GPTç¿»è¯‘
â”‚   â”œâ”€â”€ DeepSeekTranslator - DeepSeekç¿»è¯‘
â”‚   â””â”€â”€ NLLBTranslator - NLLBæœ¬åœ°ç¿»è¯‘
â”œâ”€â”€ æ ¼å¼å¤„ç†å±‚ (Format Processors)
â”‚   â”œâ”€â”€ LayoutPreserver - å¸ƒå±€ä¿æŒ
â”‚   â””â”€â”€ StyleManager - æ ·å¼ç®¡ç†
â””â”€â”€ è¾“å‡ºç”Ÿæˆå±‚ (Output Generators)
    â”œâ”€â”€ PDFGenerator - PDFç”Ÿæˆ
    â””â”€â”€ DocumentGenerator - æ–‡æ¡£ç”Ÿæˆ
```

### æ•°æ®æµç¨‹

```
è¾“å…¥æ–‡æ¡£ â†’ æ ¼å¼æ£€æµ‹ â†’ æ–‡æ¡£è§£æ â†’ æ–‡æœ¬æå– â†’ ç¿»è¯‘å¤„ç† â†’ æ ¼å¼é‡å»º â†’ è¾“å‡ºæ–‡æ¡£
```

## ğŸ“„ æ”¯æŒçš„æ–‡æ¡£æ ¼å¼

### PDFæ–‡æ¡£å¤„ç†

**æŠ€æœ¯æ ˆ**ï¼š
- `pdf2docx` - PDFåˆ°DOCXè½¬æ¢
- `PyPDF2` - PDFæ–‡æœ¬æå–
- `reportlab` - PDFç”Ÿæˆ

**å¤„ç†æµç¨‹**ï¼š

```python
# PDFç¿»è¯‘å¤„ç†æµç¨‹
from pdf2docx import Converter
from src.translation.pdf_parser import PDFParser
from src.translation.translator import TranslationEngine

def translate_pdf_with_layout(input_pdf: str, output_pdf: str, 
                             source_lang: str, target_lang: str):
    """
    ä¿æŒå¸ƒå±€çš„PDFç¿»è¯‘
    
    Args:
        input_pdf: è¾“å…¥PDFæ–‡ä»¶è·¯å¾„
        output_pdf: è¾“å‡ºPDFæ–‡ä»¶è·¯å¾„
        source_lang: æºè¯­è¨€ä»£ç 
        target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
    """
    
    # Step 1: PDFè½¬æ¢ä¸ºç»“æ„åŒ–DOCX
    temp_docx = "temp_converted.docx"
    cv = Converter(input_pdf)
    cv.convert(temp_docx, keep_layout=True)
    cv.close()
    
    # Step 2: æå–æ–‡æœ¬å†…å®¹
    parser = PDFParser()
    text_blocks = parser.extract_text_blocks(temp_docx)
    
    # Step 3: æ‰¹é‡ç¿»è¯‘
    translator = TranslationEngine.create("openai")
    translated_blocks = translator.translate_batch(
        text_blocks, source_lang, target_lang
    )
    
    # Step 4: é‡å»ºæ–‡æ¡£ç»“æ„
    parser.rebuild_document(temp_docx, translated_blocks)
    
    # Step 5: è½¬æ¢å›PDF
    parser.convert_to_pdf(temp_docx, output_pdf)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(temp_docx)
```

### PowerPointå¤„ç†

**æŠ€æœ¯æ ˆ**ï¼š
- `python-pptx` - PPTæ–‡æ¡£æ“ä½œ
- `Pillow` - å›¾åƒå¤„ç†

**æ ¸å¿ƒå®ç°**ï¼š

```python
# src/translation/ppt_parser.py
from pptx import Presentation
from typing import List, Dict, Any
import logging

class PPTParser:
    """PowerPointæ–‡æ¡£è§£æå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def extract_text_with_metadata(self, ppt_path: str) -> List[Dict[str, Any]]:
        """
        æå–æ–‡æœ¬åŠå…¶å…ƒæ•°æ®
        
        Returns:
            åŒ…å«æ–‡æœ¬ã€ä½ç½®ã€æ ·å¼ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        """
        presentation = Presentation(ppt_path)
        text_blocks = []
        
        for slide_idx, slide in enumerate(presentation.slides):
            slide_texts = self._extract_slide_text(slide, slide_idx)
            text_blocks.extend(slide_texts)
        
        return text_blocks
    
    def _extract_slide_text(self, slide, slide_idx: int) -> List[Dict[str, Any]]:
        """æå–å•ä¸ªå¹»ç¯ç‰‡çš„æ–‡æœ¬"""
        texts = []
        
        for shape_idx, shape in enumerate(slide.shapes):
            try:
                if hasattr(shape, "text") and shape.text.strip():
                    text_info = {
                        'text': shape.text,
                        'slide_index': slide_idx,
                        'shape_index': shape_idx,
                        'position': {
                            'left': shape.left,
                            'top': shape.top,
                            'width': shape.width,
                            'height': shape.height
                        },
                        'shape_type': str(shape.shape_type)
                    }
                    
                    # æå–å­—ä½“æ ·å¼ä¿¡æ¯
                    if hasattr(shape, 'text_frame'):
                        text_info['font_info'] = self._extract_font_info(shape.text_frame)
                    
                    texts.append(text_info)
                    
            except Exception as e:
                self.logger.warning(f"è·³è¿‡å¹»ç¯ç‰‡{slide_idx}å½¢çŠ¶{shape_idx}: {e}")
                continue
        
        return texts
    
    def _extract_font_info(self, text_frame) -> Dict[str, Any]:
        """æå–å­—ä½“ä¿¡æ¯"""
        font_info = {
            'font_name': None,
            'font_size': None,
            'bold': False,
            'italic': False,
            'color': None
        }
        
        try:
            for paragraph in text_frame.paragraphs:
                for run in paragraph.runs:
                    if run.font.name:
                        font_info['font_name'] = run.font.name
                    if run.font.size:
                        font_info['font_size'] = run.font.size.pt
                    font_info['bold'] = run.font.bold or False
                    font_info['italic'] = run.font.italic or False
                    break  # ä½¿ç”¨ç¬¬ä¸€ä¸ªrunçš„æ ·å¼
                break  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ®µè½çš„æ ·å¼
        except Exception as e:
            self.logger.warning(f"æå–å­—ä½“ä¿¡æ¯å¤±è´¥: {e}")
        
        return font_info
    
    def rebuild_presentation(self, original_path: str, translated_blocks: List[Dict[str, Any]], 
                           output_path: str):
        """é‡å»ºç¿»è¯‘åçš„æ¼”ç¤ºæ–‡ç¨¿"""
        presentation = Presentation(original_path)
        
        # æŒ‰å¹»ç¯ç‰‡å’Œå½¢çŠ¶ç´¢å¼•ç»„ç»‡ç¿»è¯‘æ–‡æœ¬
        translations_map = {}
        for block in translated_blocks:
            slide_idx = block['slide_index']
            shape_idx = block['shape_index']
            if slide_idx not in translations_map:
                translations_map[slide_idx] = {}
            translations_map[slide_idx][shape_idx] = block['translated_text']
        
        # åº”ç”¨ç¿»è¯‘
        for slide_idx, slide in enumerate(presentation.slides):
            if slide_idx in translations_map:
                self._apply_translations_to_slide(slide, translations_map[slide_idx])
        
        presentation.save(output_path)
    
    def _apply_translations_to_slide(self, slide, translations: Dict[int, str]):
        """å°†ç¿»è¯‘åº”ç”¨åˆ°å¹»ç¯ç‰‡"""
        for shape_idx, shape in enumerate(slide.shapes):
            if shape_idx in translations and hasattr(shape, "text"):
                try:
                    shape.text = translations[shape_idx]
                except Exception as e:
                    self.logger.warning(f"åº”ç”¨ç¿»è¯‘å¤±è´¥: {e}")
```

## ğŸ”§ ç¿»è¯‘å¼•æ“é›†æˆ

### OpenAIç¿»è¯‘å¼•æ“

```python
# src/translation/engines/openai_translator.py
import openai
from typing import List, Dict, Any
from src.utils.config import get_config

class OpenAITranslator:
    """OpenAIç¿»è¯‘å¼•æ“"""
    
    def __init__(self):
        config = get_config()
        self.client = openai.OpenAI(
            api_key=config['openai']['api_key'],
            base_url=config['openai'].get('base_url')
        )
        self.model = config['openai'].get('model', 'gpt-3.5-turbo')
    
    def translate_text(self, text: str, source_lang: str, target_lang: str) -> str:
        """ç¿»è¯‘å•ä¸ªæ–‡æœ¬"""
        prompt = f"""
        è¯·å°†ä»¥ä¸‹{source_lang}æ–‡æœ¬ç¿»è¯‘æˆ{target_lang}ï¼Œä¿æŒåŸæ–‡çš„æ ¼å¼å’Œè¯­æ°”ï¼š
        
        {text}
        
        ç¿»è¯‘ç»“æœï¼š
        """
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ï¼Œæ“…é•¿å‡†ç¡®ç¿»è¯‘å„ç§æ–‡æ¡£å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        return response.choices[0].message.content.strip()
    
    def translate_batch(self, texts: List[str], source_lang: str, 
                       target_lang: str, batch_size: int = 10) -> List[str]:
        """æ‰¹é‡ç¿»è¯‘"""
        results = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_results = []
            
            for text in batch:
                if text.strip():  # è·³è¿‡ç©ºæ–‡æœ¬
                    translated = self.translate_text(text, source_lang, target_lang)
                    batch_results.append(translated)
                else:
                    batch_results.append(text)
            
            results.extend(batch_results)
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            time.sleep(1)
        
        return results
```

### NLLBæœ¬åœ°ç¿»è¯‘å¼•æ“

```python
# src/translation/engines/nllb_translator.py
from transformers import pipeline
import torch
from typing import List, Dict

class NLLBTranslator:
    """NLLBæœ¬åœ°ç¿»è¯‘å¼•æ“"""
    
    # è¯­è¨€ä»£ç æ˜ å°„
    LANGUAGE_CODES = {
        'zh': 'zho_Hans',
        'en': 'eng_Latn',
        'ja': 'jpn_Jpan',
        'ko': 'kor_Hang',
        'fr': 'fra_Latn',
        'de': 'deu_Latn',
        'es': 'spa_Latn',
        'ru': 'rus_Cyrl'
    }
    
    def __init__(self, model_name: str = 'facebook/nllb-200-distilled-600M'):
        self.model_name = model_name
        self.device = 0 if torch.cuda.is_available() else -1
        self.translator = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½ç¿»è¯‘æ¨¡å‹"""
        try:
            self.translator = pipeline(
                'translation',
                model=self.model_name,
                device=self.device,
                model_kwargs={
                    'low_cpu_mem_usage': True,
                    'torch_dtype': torch.float16 if torch.cuda.is_available() else torch.float32
                }
            )
        except Exception as e:
            raise RuntimeError(f"NLLBæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def translate_text(self, text: str, source_lang: str, target_lang: str) -> str:
        """ç¿»è¯‘å•ä¸ªæ–‡æœ¬"""
        if not text.strip():
            return text
        
        src_code = self.LANGUAGE_CODES.get(source_lang)
        tgt_code = self.LANGUAGE_CODES.get(target_lang)
        
        if not src_code or not tgt_code:
            raise ValueError(f"ä¸æ”¯æŒçš„è¯­è¨€: {source_lang} -> {target_lang}")
        
        try:
            result = self.translator(
                text,
                src_lang=src_code,
                tgt_lang=tgt_code,
                max_length=512
            )
            return result[0]['translation_text']
        except Exception as e:
            raise RuntimeError(f"ç¿»è¯‘å¤±è´¥: {e}")
    
    def translate_batch(self, texts: List[str], source_lang: str, 
                       target_lang: str, batch_size: int = 8) -> List[str]:
        """æ‰¹é‡ç¿»è¯‘"""
        results = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_results = []
            
            for text in batch:
                translated = self.translate_text(text, source_lang, target_lang)
                batch_results.append(translated)
            
            results.extend(batch_results)
        
        return results
```

## âš™ï¸ é…ç½®ç®¡ç†

### ç¿»è¯‘é…ç½®ç»“æ„

```json
{
  "translation": {
    "default_engine": "openai",
    "engines": {
      "openai": {
        "api_key": "your_api_key",
        "model": "gpt-3.5-turbo",
        "base_url": "https://api.openai.com/v1",
        "temperature": 0.3,
        "max_tokens": 2000,
        "batch_size": 10,
        "delay_between_requests": 1.0
      },
      "deepseek": {
        "api_key": "your_deepseek_key",
        "model": "deepseek-chat",
        "base_url": "https://api.deepseek.com/v1",
        "temperature": 0.1
      },
      "nllb": {
        "model_name": "facebook/nllb-200-distilled-600M",
        "device": "auto",
        "batch_size": 8,
        "max_length": 512,
        "use_cache": true
      }
    },
    "output": {
      "format": "pdf",
      "preserve_layout": true,
      "preserve_fonts": true,
      "output_directory": "./translated_documents"
    },
    "processing": {
      "chunk_size": 1000,
      "overlap_size": 100,
      "smart_chunking": true,
      "parallel_processing": true,
      "max_workers": 4
    }
  }
}
```

### é…ç½®åŠ è½½å™¨

```python
# src/utils/translation_config.py
import json
from pathlib import Path
from typing import Dict, Any

class TranslationConfig:
    """ç¿»è¯‘é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = None):
        self.config_path = config_path or "config/translation_config.json"
        self.config = self._load_config()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = Path(self.config_path)
        
        if not config_file.exists():
            return self._get_default_config()
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            raise RuntimeError(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "translation": {
                "default_engine": "nllb",
                "engines": {
                    "nllb": {
                        "model_name": "facebook/nllb-200-distilled-600M",
                        "device": "auto",
                        "batch_size": 8
                    }
                },
                "output": {
                    "format": "pdf",
                    "preserve_layout": True
                }
            }
        }
    
    def get_engine_config(self, engine_name: str) -> Dict[str, Any]:
        """è·å–ç‰¹å®šå¼•æ“çš„é…ç½®"""
        engines = self.config.get("translation", {}).get("engines", {})
        return engines.get(engine_name, {})
    
    def get_output_config(self) -> Dict[str, Any]:
        """è·å–è¾“å‡ºé…ç½®"""
        return self.config.get("translation", {}).get("output", {})
    
    def save_config(self, config: Dict[str, Any]):
        """ä¿å­˜é…ç½®"""
        config_file = Path(self.config_path)
        config_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        self.config = config
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ç¿»è¯‘ç¤ºä¾‹

```python
# åŸºç¡€PDFç¿»è¯‘
from src.translation.processor import DocumentProcessor

processor = DocumentProcessor()
result = processor.translate_document(
    input_path="document.pdf",
    output_path="translated_document.pdf",
    source_lang="zh",
    target_lang="en",
    engine="openai"
)

if result.success:
    print(f"ç¿»è¯‘å®Œæˆ: {result.output_path}")
else:
    print(f"ç¿»è¯‘å¤±è´¥: {result.error_message}")
```

### æ‰¹é‡ç¿»è¯‘ç¤ºä¾‹

```python
# æ‰¹é‡æ–‡æ¡£ç¿»è¯‘
from src.translation.batch_processor import BatchTranslationProcessor

processor = BatchTranslationProcessor()
files = ["doc1.pdf", "doc2.pptx", "doc3.docx"]

results = processor.process_batch(
    input_files=files,
    output_directory="./translated",
    source_lang="zh",
    target_lang="en",
    engine="nllb",
    parallel=True
)

for result in results:
    if result.success:
        print(f"âœ… {result.input_file} -> {result.output_file}")
    else:
        print(f"âŒ {result.input_file}: {result.error_message}")
```

### è‡ªå®šä¹‰ç¿»è¯‘æµç¨‹

```python
# è‡ªå®šä¹‰ç¿»è¯‘æµç¨‹
from src.translation.engines import TranslationEngineFactory
from src.translation.parsers import DocumentParserFactory

# åˆ›å»ºè§£æå™¨å’Œç¿»è¯‘å¼•æ“
parser = DocumentParserFactory.create_parser(".pdf")
translator = TranslationEngineFactory.create_engine("openai")

# æå–æ–‡æœ¬
text_blocks = parser.extract_text_with_metadata("input.pdf")

# ç¿»è¯‘æ–‡æœ¬
translated_blocks = []
for block in text_blocks:
    translated_text = translator.translate_text(
        block['text'], "zh", "en"
    )
    block['translated_text'] = translated_text
    translated_blocks.append(block)

# é‡å»ºæ–‡æ¡£
parser.rebuild_document("input.pdf", translated_blocks, "output.pdf")
```

## ğŸ” è°ƒè¯•å’Œæ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **PPTå½¢çŠ¶ç±»å‹é”™è¯¯**
   ```python
   # è§£å†³æ–¹æ¡ˆï¼šæ·»åŠ å¼‚å¸¸å¤„ç†
   try:
       shape_text = shape.text
   except Exception as e:
       logger.warning(f"è·³è¿‡æœªçŸ¥å½¢çŠ¶ç±»å‹: {e}")
       continue
   ```

2. **å†…å­˜ä¸è¶³**
   ```python
   # è§£å†³æ–¹æ¡ˆï¼šåˆ†å—å¤„ç†
   def process_large_document(file_path, chunk_size=1000):
       for chunk in split_document(file_path, chunk_size):
           process_chunk(chunk)
   ```

3. **APIé™åˆ¶**
   ```python
   # è§£å†³æ–¹æ¡ˆï¼šæ·»åŠ é‡è¯•å’Œå»¶è¿Ÿ
   import time
   from tenacity import retry, stop_after_attempt, wait_exponential
   
   @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
   def translate_with_retry(text, source_lang, target_lang):
       return translator.translate_text(text, source_lang, target_lang)
   ```

### æ—¥å¿—é…ç½®

```python
# ç¿»è¯‘åŠŸèƒ½ä¸“ç”¨æ—¥å¿—é…ç½®
import logging

def setup_translation_logging():
    """è®¾ç½®ç¿»è¯‘åŠŸèƒ½æ—¥å¿—"""
    logger = logging.getLogger('translation')
    logger.setLevel(logging.INFO)
    
    handler = logging.FileHandler('logs/translation.log')
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    return logger
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜ç­–ç•¥

```python
# ç¿»è¯‘ç»“æœç¼“å­˜
from functools import lru_cache
import hashlib

class TranslationCache:
    def __init__(self):
        self.cache = {}
    
    def get_cache_key(self, text: str, source_lang: str, target_lang: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{text}|{source_lang}|{target_lang}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def get_translation(self, text: str, source_lang: str, target_lang: str) -> str:
        """è·å–ç¼“å­˜çš„ç¿»è¯‘"""
        key = self.get_cache_key(text, source_lang, target_lang)
        return self.cache.get(key)
    
    def cache_translation(self, text: str, source_lang: str, 
                         target_lang: str, translation: str):
        """ç¼“å­˜ç¿»è¯‘ç»“æœ"""
        key = self.get_cache_key(text, source_lang, target_lang)
        self.cache[key] = translation
```

### å¹¶è¡Œå¤„ç†

```python
# å¹¶è¡Œç¿»è¯‘å¤„ç†
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Callable

class ParallelTranslationProcessor:
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
    
    def process_parallel(self, texts: List[str], 
                        translation_func: Callable) -> List[str]:
        """å¹¶è¡Œå¤„ç†ç¿»è¯‘"""
        results = [None] * len(texts)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_index = {
                executor.submit(translation_func, text): i 
                for i, text in enumerate(texts)
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    results[index] = future.result()
                except Exception as e:
                    results[index] = f"ç¿»è¯‘å¤±è´¥: {e}"
        
        return results
```

## ğŸ“š æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„ç¿»è¯‘å¼•æ“

```python
# æ–°ç¿»è¯‘å¼•æ“ç¤ºä¾‹
from abc import ABC, abstractmethod

class BaseTranslationEngine(ABC):
    """ç¿»è¯‘å¼•æ“åŸºç±»"""
    
    @abstractmethod
    def translate_text(self, text: str, source_lang: str, target_lang: str) -> str:
        """ç¿»è¯‘å•ä¸ªæ–‡æœ¬"""
        pass
    
    @abstractmethod
    def translate_batch(self, texts: List[str], source_lang: str, 
                       target_lang: str) -> List[str]:
        """æ‰¹é‡ç¿»è¯‘"""
        pass

class CustomTranslationEngine(BaseTranslationEngine):
    """è‡ªå®šä¹‰ç¿»è¯‘å¼•æ“"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        # åˆå§‹åŒ–è‡ªå®šä¹‰å¼•æ“
    
    def translate_text(self, text: str, source_lang: str, target_lang: str) -> str:
        # å®ç°è‡ªå®šä¹‰ç¿»è¯‘é€»è¾‘
        pass
    
    def translate_batch(self, texts: List[str], source_lang: str, 
                       target_lang: str) -> List[str]:
        # å®ç°æ‰¹é‡ç¿»è¯‘é€»è¾‘
        pass

# æ³¨å†Œæ–°å¼•æ“
TranslationEngineFactory.register_engine("custom", CustomTranslationEngine)
```

### æ·»åŠ æ–°çš„æ–‡æ¡£æ ¼å¼æ”¯æŒ

```python
# æ–°æ–‡æ¡£æ ¼å¼è§£æå™¨
class ExcelParser(BaseDocumentParser):
    """Excelæ–‡æ¡£è§£æå™¨"""
    
    def extract_text_with_metadata(self, file_path: str) -> List[Dict[str, Any]]:
        """æå–Excelæ–‡æœ¬å’Œå…ƒæ•°æ®"""
        import openpyxl
        
        workbook = openpyxl.load_workbook(file_path)
        text_blocks = []
        
        for sheet_name in workbook.sheetnames:
            sheet = workbook[sheet_name]
            for row in sheet.iter_rows(values_only=True):
                for col_idx, cell_value in enumerate(row):
                    if cell_value and isinstance(cell_value, str):
                        text_blocks.append({
                            'text': cell_value,
                            'sheet': sheet_name,
                            'row': row[0].row,
                            'column': col_idx + 1
                        })
        
        return text_blocks
    
    def rebuild_document(self, original_path: str, translated_blocks: List[Dict[str, Any]], 
                        output_path: str):
        """é‡å»ºExcelæ–‡æ¡£"""
        # å®ç°Excelé‡å»ºé€»è¾‘
        pass

# æ³¨å†Œæ–°è§£æå™¨
DocumentParserFactory.register_parser(".xlsx", ExcelParser)
```

---

*æœ¬æ–‡æ¡£å°†éšç€åŠŸèƒ½å‘å±•æŒç»­æ›´æ–°*